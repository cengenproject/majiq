#!/bin/bash
#SBATCH --partition=general
#SBATCH --job-name=majiq6
#SBATCH -c 15
#SBATCH --mem=15G
#SBATCH --time=3-05:10:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=alexis.weinreb@yale.edu


# MAJIQ workflow v3: in v2 grouped all the biological and technical replicates by neuron. In v3, group the technical replicates (if any) by biological replicate.
# MAJIQ v4: use the merged bams (no technical replicate), group the biological replicates by neuron
# v5: also perform tests for every neuron pair
# v6: add modulizer
# v7: prepare ref with gene names and add heterogen



# ----------------------------------------------------------------------------
# -----------------------    Parameters definitions   ------------------------
# ---------------------------------------------------------------------------- 

# Locations and parameters
#bam_dir='/SAY/standard/mh588-CC1100-MEDGEN/bulk_alignments/bsn3'
bam_dir='/home/aw853/scratch60/2022-03-18_alignments'

outdir='/gpfs/ycga/project/ysm/hammarlund/aw853/counts/majiq/outs/2022-03-23_outs'


WSversion='WS281'

# If using the WormBase reference
# references_dir='/gpfs/ycga/project/ysm/hammarlund/aw853/references'
# gff_conversion="gtf2gff3" # or gffread
# ref_gff_name='c_elegans.PRJNA13758.'$WSversion'.canonical_geneset_'$gff_conversion'.gff3'
# ref_gff=$references_dir'/'$WSversion'/'$ref_gff_name

# GTF generated by StringTie mix, then filtered
gtf_with_novel='/home/aw853/project/stringtie_quantif/intermediates/2022-03-22_str_sc_n/220322_novel_filt_sorted.gtf'

# names for intermediates
gtf_prepared='intermediates/220322_novel_filt_nogene.gtf'
ref_gff='intermediates/220322_novel_filt.gff3'


# ----------------------------------------------------------------------------
# ---------      No modification required below this line     ----------------
# ----------------------------------------------------------------------------


set -e

echo
echo
echo "Starting majiq (config, build, quantif, modulize, test v7), $(date)"
echo


echo "Process gtf"

# Process reference gtf into a gff with gene names
awk -f src/add_gene_names.awk $gtf_with_novel $gtf_with_novel \
    | sed 's/\tStringTie\t/\tWormBase\t/' \
    > $gtf_prepared

/home/aw853/bin/gtf2gff3.pl \
    --cfg /home/aw853/project/references/gtf2gff3.cfg \
    $gtf_prepared \
    > $ref_gff



cfg_file=$outdir/$(date +%F)_majiq.cfg


# the output subdirectories
mkdir -p $outdir/build
mkdir -p $outdir/psi
mkdir -p $outdir/logs
mkdir -p $outdir/voila_modulizer
mkdir -p $outdir/deltapsi
#mkdir -p $outdir/heterogen


source /home/aw853/bin/majiq_v2-3/env/bin/activate
module load Python/3.8.6-GCCcore-10.2.0 HTSlib/1.12-GCCcore-10.2.0





# --------    End definitions, start computations    --------


echo


# Create gff3 from gtf if needed
if [[ ! -f $ref_gff ]]
then
  echo "GFF3 file doesn't exist. Create it with $gff_conversion"
  exit 1
fi


echo "--------   List samples to process   --------"

samplelist=($(ls $bam_dir/*bam | xargs basename -a -s .bam))
declare -A sampByNeur #for the config file to the BUILD command
declare -A sampByNeur_path # for the PSI command
declare -A all_samp # for the HET command

for smp in "${samplelist[@]}"
do
	if [[ $smp =~ ^([A-Z1-9ef]{2,4})r[0-9]{1,4}[t12]*$ ]]
	then
	  all_samp[$smp]=${BASH_REMATCH[1]}
	  
		if [[ -z ${sampByNeur[${BASH_REMATCH[1]}]} ]]
		then
			#first time that neuron encountered
			sampByNeur[${BASH_REMATCH[1]}]="${BASH_REMATCH[1]}=$smp"
			sampByNeur_path[${BASH_REMATCH[1]}]=$outdir/build/$smp.majiq
		else
			#neuron already initialized
			sampByNeur[${BASH_REMATCH[1]}]+=","$smp
			sampByNeur_path[${BASH_REMATCH[1]}]+=" $outdir/build/$smp.majiq"
		fi
	else
		#no match
		echo "Error matching regex for sample $smp"
		exit 1
	fi
done


# remove the Ref samples that we don't want here
unset sampByNeur[Ref]
unset sampByNeur_path[Ref]

for smp in "${!all_samp[@]}"
do
  if [[ ${all_samp[$smp]} == "Ref" ]]
  then
    unset all_samp[$smp]
  fi
done




echo "--------     Create config file     --------"

echo "[info]
bamdirs=$bam_dir
genome=$WSversion
strandness=forward
[experiments]" > $cfg_file

printf "%s\n" ${sampByNeur[@]} >> $cfg_file

echo "Config file generated and saved as $cfg_file"




echo "##################################################################"
echo "##################             Build            ##################"
echo "##################################################################"
echo
echo



# build ----

echo
echo "Running MAJIQ build on $(date) with $gff_conversion and autocreated conf file"
echo




# --min-experiments  fraction or number of experiments that must pass filters [Default: 0.5]
#
###     SJ filters
# --minreads    minimum nb of reads for SJ [Default: 3]
# --minpos      min nb of read positions [Default: 2]
# --min-denovo  min nb reads on de-novo SJ [Default: 5]
#
###     Intron retention filters
# --irnbins           fraction of intronic read positions that must pass min-intronic-cov [Default: 0.5]
# --min-intronic-cov  min per-position normalized intronic readrate [Default: 0.01]
# 
# Simplifier options:
# 
#     --simplify simplification ignores junctions and introns with low usage [Default: -1] 

# Bootstrap coverage sampling:
# 
#     --markstacks p-value threshold used for dremoving read stacks [Default: 1e-07]
#     --m number of bootstraps to save in output SJ and MAJIQ files [Default: 30]

majiq build --nproc $SLURM_CPUS_PER_TASK \
			-o $outdir/build \
			--conf $cfg_file \
			--min-experiments 2 \
			--logger $outdir/logs \
			$ref_gff

echo "Finished the build step."
echo





echo "##################################################################"
echo "##################             PSI              ##################"
echo "##################################################################"
echo
echo


echo 
echo "Running MAJIQ PSI on $(date) with conf $cfg_file"
echo


# --minreads min nb of reads at any positions in a LSV [Default: 10]
# --minpos min nb of start positions with at least 1 read in a LSV to considered. [Default: 3]
# --min-experiments Use to alter the threshold for group filters.
# --output-type {voila,tsv,all} Specify the type(s) of output files to produce
#   
for neur in ${!sampByNeur_path[@]}
do
	echo "---- PSI for $neur ----"
	majiq psi --output $outdir/psi \
		  --name $neur \
		  --nproc $SLURM_CPUS_PER_TASK \
		  --output-type all \
		  --logger $outdir/logs \
		  ${sampByNeur_path[$neur]}
done


echo "##################################################################"
echo "##################           Modulize           ##################"
echo "##################################################################"
echo
echo


# modulize ----

echo 
echo "Running Voila Modulizer on $(date)"
echo


voila modulize \
  --overwrite \
  --nproc $SLURM_CPUS_PER_TASK \
  --logger $outdir/logs \
  --keep-constitutive --keep-no-lsvs-modules --keep-no-lsvs-junctions \
  -d $outdir/voila_modulizer \
  $outdir/psi $outdir/build/splicegraph.sql

echo "------------ End modulizer ------------"
echo



echo "##################################################################"
echo "##################           DeltaPSI           ##################"
echo "##################################################################"
echo
echo



echo 
echo "Running MAJIQ DeltaPSI on $(date) with conf $cfg_file"
echo

# get the neuron names in a non-associative array
all_neurs=(${!sampByNeur[@]})

for ((  i = 0; i < ${#all_neurs[@]}; i++ ))
do
  for (( j = $i+1; j < ${#all_neurs[@]}; j++))
	do
	  echo "---------------"
		
		neurA=${all_neurs[$i]}
		neurB=${all_neurs[$j]}
		
		echo "i: $i , j: $j ; Testing $neurA vs $neurB"
		echo
		
		
    # Mandatory arguments:
    # 
    #   -grp1 FILES1 [FILES1 ...]: Set of .majiq file[s] for the first condition
    #   -grp2 FILES2 [FILES2 ...]: Set of .majiq file[s] for the second condition
    #   -n/--names NAMES [NAMES ...]: _cond_id1_ _cond_id2_: group identifiers for grp1 and grp2 respectively.
    #   -o/--output OUTDIR: PSI output directory. It will contain the deltapsi.voila file once the execution is finished.
    # 
    # Optional arguments:
    # 
    #   --minreads MINREADS: Minimum number of reads [Default: 10]
    #   --minpos MINPOS: Minimum number of start positions [Default: 3]
    #   --min-experiments MIN_EXP: Use to alter the threshold for group filters.
    #   --binsize BINSIZE: The bins for PSI values. With a BINSIZE of 0.025 (default), we have 40 bins
    #   --default-prior: Use a default prior instead of computing it using the empirical data
    #   --prior-minreads PRIORMINREADS: Minimum number of reads (for the 'best set' calculation). [Default: 20]
    #   --prior-minnonzero PRIORMINNONZERO: Minimum number of positions for the best set.
    #   --prior-iter ITER: Max number of iterations of the EM
    #   --output-type {voila,tsv,all} Specify the type(s) of output files to produce [Default: all]

		majiq deltapsi \
		  -grp1 ${sampByNeur_path[$neurA]} \
		  -grp2 ${sampByNeur_path[$neurB]} \
		  -n $neurA $neurB \
		  -o $outdir/deltapsi \
		  --nproc $SLURM_CPUS_PER_TASK \
		  --output-type all \
		  --logger $outdir/logs
		
		echo
		
	done
done



echo "------------ End DeltaPSI ------------"
echo

echo "##################################################################"
echo "##################           Heterogen          ##################"
echo "##################################################################"
echo
echo



echo 
echo "Running MAJIQ heterogen on $(date) with conf $cfg_file"
echo

# get indexed arrays
# all_samp_smp=(${!all_samp[@]})
# all_samp_neu=(${all_samp[@]})

for ((  i = 0; i < ${#all_samp[@]}; i++ ))
do
  for (( j = $i+1; j < ${#all_samp[@]}; j++))
	do
	  echo "---------------"

		# sampA=${all_samp_smp[$i]}
		# sampB=${all_samp_smp[$j]}

		neurA=${all_samp_neu[$i]}
		neurB=${all_samp_neu[$j]}

		echo "i: $i , j: $j ; Testing $neurA vs $neurB "
		echo


    # usage: majiq heterogen [-h] [-j NPROC] -o OUTDIR [--logger LOGGER] [--silent] [--debug] [--mem-profile] [--min-experiments MIN_EXP] [--minreads MINREADS] [--minpos MINPOS] -grp1 FILES1 [FILES1 ...] -grp2
    #                        FILES2 [FILES2 ...] -n NAME_GRP1 NAME_GRP2 [--keep-tmpfiles] [--psi-samples PSI_SAMPLES] [--stats {TTEST,WILCOXON,TNOM,INFOSCORE,ALL} [{TTEST,WILCOXON,TNOM,INFOSCORE,ALL} ...]]
    #                        [--test_percentile TEST_PERCENTILE] [--visualization-std VISUALIZATION_STD]
    #
    #   --psi-samples PSI_SAMPLES
    #                         Number of PSI samples to take per LSV junction. If equal to 0, use expected value only. [Default: 100]
    #   --stats {TTEST,WILCOXON,TNOM,INFOSCORE,ALL} [{TTEST,WILCOXON,TNOM,INFOSCORE,ALL} ...]
    #                         Test statistics to run. TTEST: unpaired two-sample t-test (Welch's t-test).
    #                                                 WILCOXON: Mann-Whitney U two-sample test (nonparametric).
    #                                                 TNOM: Total Number of Mistakes (nonparametric).
    #                                                 INFOSCORE: TNOM but threshold maximizing mutual information with group labels (nonparametric).
    #                                                 ALL: use all other available test statistics. [Default: ['TTEST', 'WILCOXON', 'TNOM']]
    #   --test_percentile TEST_PERCENTILE
    #                         For each one of the statistical tests, we combine all pvalue per psi sample by percentile calculation. This argument allows the user define with percentile they want to use [Default:
    #                         0]
    #   --visualization-std VISUALIZATION_STD
    #                         Change stochastic estimation error in terms of standard deviation of discretized average posterior per group by sampling additional values of PSI when number of samples is low
    #                         [Default: 0.010000]
    #
    # Required specification of groups:
    #   -grp1 FILES1 [FILES1 ...]
    #                         Paths to MAJIQ files for the experiment(s) to quantify for first group (aggregated as replicates if deltapsi, independently if heterogen)
    #   -grp2 FILES2 [FILES2 ...]
    #                         Paths to MAJIQ files for the experiment(s) to quantify for first group (aggregated as replicates if deltapsi, independently if heterogen)
    #   -n NAME_GRP1 NAME_GRP2, --names NAME_GRP1 NAME_GRP2
    #                         The names that identify the groups being compared.

		majiq heterogen \
		  -grp1 ${sampByNeur_path[$neurA]} \
		  -grp2 ${sampByNeur_path[$neurB]} \
		  --names $neurA $neurB \
		  -o $outdir/heterogen \
		  --psi-samples 100 \
		  --nproc $SLURM_CPUS_PER_TASK \
		  --logger $outdir/logs

		echo

	done
done



echo "------------ End heterogen ------------"
echo



echo "##################################################################"
echo "##################################################################"
echo
echo





# export relevant data ----
mv $outdir/build/splicegraph.sql $outdir/splicegraph.sql
mv $outdir/build/majiq.log $outdir/logs/majiq_build.log
mv $outdir/psi/psi_majiq.log $outdir/logs/majiq_psi.log
mv $outdir/deltapsi/deltapsi_majiq.log $outdir/logs/majiq_deltapsi.log
mv $outdir/heterogen/heterogen_majiq.log $outdir/logs/majiq_heterogen.log
mv $outdir/voila_modulizer/voila.log $outdir/logs/voila_modulizer.log


# to download on local computer for Voila and R analyses, then can be deleted from cluster
tar -czf $outdir/$(date +%y%m%d)_mjq_exprt.tar.gz $outdir/deltapsi/*.tsv $outdir/voila_modulizer/*.tsv

echo
echo "All done $(date)"
